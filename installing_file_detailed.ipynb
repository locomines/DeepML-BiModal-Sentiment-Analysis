{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lancement du code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je présente ici les différents bugs que j'ai dû résoudre lors du lancement du code initial du repo GitHub. J'ai réalisé un certain nombre de mini-modifs pour faire fonctionner le code (qui n'a pas de ReadME). Je conseille donc de prendre mon code et mon repo Github plutot que l'original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n GNN\n",
    "conda activate GNN\n",
    "cd <path_name>\n",
    "conda config --env --add channels pytorch\n",
    "conda install python\n",
    "conda install pip\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "'''conda install pytorch torchvision''' # lancer cela si vous n'êtes pas sur Mac. \n",
    "conda install pytorch torchvision cpuonly -c pytorch # lancer cela si vous êtes sur Mac. Il s'agit de la version cpuonly de pytorch.\n",
    "# Sans cela j'ai un message d'erreur plus tard de 'AssertionError: Torch not compiled with CUDA enabled' car les Mac n'ont pas de GPU CUDA capable.\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "conda install cudatoolkit # je pense qu'on en a donc pas besoin si on est sur Mac\n",
    "conda install -c dglteam dgl\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "CUDA_VISIBLE_DEVICES=1 python Tumblr_Multi_GCN_Multihead_Att.py  --image-size 448 --batch-size 4 -e --text_min_count 7 --ngram 5 --window_size 5 --epochs 10 --lr 5e-5 --object_t_value 0.6 --place_t_value 0.5 --model_name Multi_GCN_Multihead_Att\n",
    "'''\n",
    "# MEssage d'erreur : \n",
    "# DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
    "# Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "conda install word2vec\n",
    "# bien replacer tumblr_label_glove.pkl dans data/glove\n",
    "conda install torchnet\n",
    "pip install torchnet\n",
    "conda install scikit-learn # bien scikit-learn et non pas sklearn\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# Il me manque le module 'apex', pour cela il faut retrouver le repo github de ce module, et suivre les instruction du README. Lien du github : https://github.com/NVIDIA/apex\n",
    "# Il faut alors RUN:\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "cd apex\n",
    "pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "# apex. amp is a tool to enable mixed precision training by changing only 3 lines of your script.\n",
    "# On obtient alors un dossier apex, avec à l'intérieur plusieurs dossier dont un sous-dossier 'apex'.\n",
    "# Il faut sortir les fichier de ce sous dossier apex et les mettre dans le dossier apex (les remonter d'un cran, et supprimer le sous-dossier 'apex' alors vide)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# # La commande initiale devrait alors fonctionner mais on va d'abord installer le package 'syncbn' qui est un package qui permet de faire du calcul parallèle par mini batch pendant le training.\n",
    "# # Il faut alors retrouver le lien du github: https://github.com/shinsumicco/pytorch-syncbn\n",
    "# # Cloner d'abord le repo, puis cd, puis télécharger les requirements, puis run le fichier setup de ce nouveau module, puis set the environment variable PYTHONPATH comme demandé.\n",
    "# git clone https://github.com/shinsumicco/pytorch-syncbn\n",
    "# cd pytorch-syncbn\n",
    "# pip install -r requirements.txt\n",
    "# python setup.py [--cuda-path CUDA_PATH]\n",
    "# nvcc: NVIDIA (R) Cuda compiler driver\n",
    "# Copyright (c) 2005-2016 NVIDIA Corporation\n",
    "# Built on Sun_Sep__4_22:14:01_CDT_2016\n",
    "# Cuda compilation tools, release 8.0, V8.0.44\n",
    "# => building CUDA kernel\n",
    "# => creating PyTorch extension\n",
    "# cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C\n",
    "# cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
    "# cc1plus: warning: command line option ‘-std=c99’ is valid for C/ObjC but not for C++\n",
    "# => Please set PYTHONPATH as follows:\n",
    "\n",
    "# export PYTHONPATH=\"/path/to/dir/of/pytorch-syncbn:$PYTHONPATH\"\n",
    "\n",
    "# # En fait pas besoin de ca, il s'gait d'une librairie de calcul parallèle avec plusieurs GPU. On se contentera d'un seul GPU :  celui de mon ordi\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Modification d'une partie du code : dans models/Multi_GCN_Multihead_att.py, ligne 162, on avait avant:\n",
    "'''model = word2vec.load(word2vec_file)'''\n",
    "# Or notre fichier word2vec_file ('data/glove/glove.6B.300d.txt') est en fait un fichier d'embedding 'Glove' et non pas 'Word2vec'. Ainsi la méthode word2vec.load n'est pas adaptée. \n",
    "# On obtient comme message d'erreur : ValueError: invalid literal for int() with base 10: b'the'\n",
    "# Il faut en fait changer la méthode de lecteur de notre fichier. Je l'ai modifiée de la manière suivante : \n",
    "\n",
    "embeddings_dict = {}\n",
    "with open(word2vec_file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "\n",
    "# On remplace aussi model par embeddings_dict dans 'embedding_matrix.append(embeddings_dict[word ou 'the'])'\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# Obtention d'un message d'erreur : FileNotFoundError: [Errno 2] No such file or directory: 'data/all_anno_json_new/train_all_anno.json'\n",
    "# Modification de 4 lignes du fichier Text_GCN.py : ligne 20, 28, 53 et 67: supprimer le '.new' a chaque fois.\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# Message d'erreur  : \n",
    "'''\n",
    "File \"/Users/gaetanpinon/opt/anaconda3/envs/GNN/lib/python3.10/site-packages/word2vec/wordvectors.py\", line 233, in from_text\n",
    "    with open(fname, 'r') as fin:\n",
    "FileNotFoundError: [Errno 2] No such file or directory: 'glove/glove.6B.300d.txt'\n",
    "'''\n",
    "# Modifier dans Text_GCN : ligne 76 : rajouter data/ devant /glove/glove.6B.300d.txt'\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Même erreur Glove vs Word2vec que dans le fichier models/Multi_GCN_Multihead_att.py, mais dans models/Text_GCN.py\n",
    "# De la même manière, on modifie avec \n",
    "embeddings_dict = {}\n",
    "with open(word2vec_file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "# Puis On remplace aussi model par embeddings_dict dans 'embedding_matrix.append(embeddings_dict[word ou 'the'])'\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# MEssage d'erreur : \n",
    "'''\n",
    "AssertionError: Torch not compiled with CUDA enabled\n",
    "'''\n",
    "# Cela vient du fait de la méthode \n",
    "torch.sqrt(torch.FloatTensor([hid_dim // n_heads])).to(device) #ligne 86\n",
    "# qui utilise une fonctionnalité CUDA GPU capable pour du calcul parallèle. Or un MAc (mon cas) n'est pas CUDA GPU capable. C'est pourquoi j'ai intallé la version cpuonly de pytorch et torchvision au départ\n",
    "# remplacer to(device) par to('cpu') et ca devrait fonctionner.\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# Message d'erreur :\n",
    "'''\n",
    "object_adj, object_nums = gen_A(object_num_classes, self.object_t, object_adj_file)\n",
    "TypeError: gen_A() missing 1 required positional argument: 'gama'\n",
    "'''\n",
    "# Modifier la ligne 382 de utils/util.py : rajouter gama=0.2 valeur par défault proposée par l'auteur\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "# Vient maintenant le problème de la base de données TumEmo qui n'est pas en open source. Message d'erreur : \n",
    "'''\n",
    "FileNotFoundError: [Errno 2] No such file or directory: 'data/image_data/train_image/127462.jpg'\n",
    "'''\n",
    "# Tout simplement car nous n'avons pas la base de données. Il s'agit d'une base de données image-texte de réseaux sociaux contrsuite expréssément par les auteurs de notre article.\n",
    "# Voici la référence de l'article où ils présentent leur base de données : https://ieeexplore.ieee.org/document/9246699\n",
    "# Mais cette base de données n'est pas en open source donc il faut leur demander. Je leur ai écrit 2 mails : un avec mon adresse mail universitaire, l'autre avec mon adresse perso. J'ai aussi fait une request full text sur le site 'Research Gate'. J'ai n'ai pour l'instant aucun retour (31 Janvier 2023).\n",
    "# Une autre solution serait d'y accéder grâce à une license universitaire. Mines Nancy n'en a pas pour le site ieeeexplore.ieee.org, mais Mines Saint Etienne en a apparemment une. Peut être pourrait on leur demander l'accès.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
